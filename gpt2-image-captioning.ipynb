{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "afb3b1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "test_valid_percentage = 20 # (test - 10, valid - 10)\n",
    "\n",
    "train_data_percentage = 20\n",
    "valid_data_percentage = 40\n",
    "test_data_percentage = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2b4bfcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ebad4194",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import VisionEncoderDecoderModel, AutoFeatureExtractor,AutoTokenizer\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b2bf09d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "try:\n",
    "    nltk.data.find(\"tokenizers/punkt\")\n",
    "except (LookupError, OSError):\n",
    "    nltk.download(\"punkt\", quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0da5f5",
   "metadata": {},
   "source": [
    "## Initialize VisionEncoderDecoderModelPermalink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5e834dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.3.crossattention.c_attn.bias', 'h.9.crossattention.c_proj.bias', 'h.5.crossattention.c_proj.bias', 'h.7.ln_cross_attn.weight', 'h.2.crossattention.q_attn.weight', 'h.7.crossattention.c_proj.weight', 'h.9.crossattention.q_attn.weight', 'h.6.ln_cross_attn.bias', 'h.7.crossattention.c_attn.weight', 'h.5.ln_cross_attn.weight', 'h.8.crossattention.c_proj.bias', 'h.5.crossattention.c_attn.weight', 'h.1.crossattention.c_proj.weight', 'h.6.crossattention.c_attn.bias', 'h.6.crossattention.c_attn.weight', 'h.9.ln_cross_attn.weight', 'h.0.crossattention.q_attn.bias', 'h.1.crossattention.c_attn.weight', 'h.10.crossattention.c_proj.weight', 'h.5.crossattention.q_attn.weight', 'h.4.crossattention.q_attn.weight', 'h.4.ln_cross_attn.weight', 'h.1.crossattention.q_attn.bias', 'h.0.ln_cross_attn.bias', 'h.6.crossattention.c_proj.weight', 'h.4.ln_cross_attn.bias', 'h.2.crossattention.c_attn.bias', 'h.3.crossattention.c_proj.weight', 'h.0.crossattention.c_proj.weight', 'h.2.crossattention.c_proj.weight', 'h.8.crossattention.q_attn.bias', 'h.0.crossattention.q_attn.weight', 'h.0.crossattention.c_attn.bias', 'h.8.crossattention.q_attn.weight', 'h.3.ln_cross_attn.bias', 'h.8.ln_cross_attn.bias', 'h.2.crossattention.q_attn.bias', 'h.11.ln_cross_attn.weight', 'h.6.crossattention.q_attn.weight', 'h.4.crossattention.c_attn.bias', 'h.11.ln_cross_attn.bias', 'h.11.crossattention.c_attn.bias', 'h.7.crossattention.q_attn.bias', 'h.1.crossattention.c_attn.bias', 'h.4.crossattention.c_proj.weight', 'h.3.crossattention.c_proj.bias', 'h.11.crossattention.c_attn.weight', 'h.3.crossattention.q_attn.weight', 'h.10.crossattention.q_attn.weight', 'h.1.crossattention.q_attn.weight', 'h.1.crossattention.c_proj.bias', 'h.4.crossattention.c_proj.bias', 'h.1.ln_cross_attn.weight', 'h.11.crossattention.c_proj.weight', 'h.2.crossattention.c_proj.bias', 'h.8.crossattention.c_attn.weight', 'h.10.ln_cross_attn.weight', 'h.2.crossattention.c_attn.weight', 'h.8.ln_cross_attn.weight', 'h.9.ln_cross_attn.bias', 'h.10.crossattention.c_attn.bias', 'h.6.crossattention.q_attn.bias', 'h.0.crossattention.c_attn.weight', 'h.7.crossattention.c_proj.bias', 'h.11.crossattention.q_attn.weight', 'h.7.crossattention.c_attn.bias', 'h.9.crossattention.c_proj.weight', 'h.6.crossattention.c_proj.bias', 'h.1.ln_cross_attn.bias', 'h.3.crossattention.c_attn.weight', 'h.3.ln_cross_attn.weight', 'h.11.crossattention.c_proj.bias', 'h.0.ln_cross_attn.weight', 'h.10.crossattention.c_proj.bias', 'h.4.crossattention.c_attn.weight', 'h.10.crossattention.c_attn.weight', 'h.5.crossattention.q_attn.bias', 'h.0.crossattention.c_proj.bias', 'h.5.crossattention.c_attn.bias', 'h.9.crossattention.c_attn.bias', 'h.2.ln_cross_attn.bias', 'h.11.crossattention.q_attn.bias', 'h.7.ln_cross_attn.bias', 'h.9.crossattention.q_attn.bias', 'h.7.crossattention.q_attn.weight', 'h.8.crossattention.c_attn.bias', 'h.5.crossattention.c_proj.weight', 'h.4.crossattention.q_attn.bias', 'h.10.crossattention.q_attn.bias', 'h.2.ln_cross_attn.weight', 'h.3.crossattention.q_attn.bias', 'h.8.crossattention.c_proj.weight', 'h.9.crossattention.c_attn.weight', 'h.6.ln_cross_attn.weight', 'h.10.ln_cross_attn.bias', 'h.5.ln_cross_attn.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import VisionEncoderDecoderModel, AutoTokenizer, AutoFeatureExtractor\n",
    "\n",
    "image_encoder_model = \"google/vit-base-patch16-224-in21k\"\n",
    "text_decode_model = \"gpt2\"\n",
    "\n",
    "model = VisionEncoderDecoderModel.from_encoder_decoder_pretrained(image_encoder_model, text_decode_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "569f7a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohith/opt/anaconda3/lib/python3.9/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# image feature extractor\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(image_encoder_model)\n",
    "# text tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(text_decode_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3d5170ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT2 only has bos/eos tokens but not decoder_start/pad tokens\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# update the model config\n",
    "model.config.eos_token_id = tokenizer.eos_token_id\n",
    "model.config.decoder_start_token_id = tokenizer.bos_token_id\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "46dc055f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('vit-gpt-model/tokenizer_config.json',\n",
       " 'vit-gpt-model/special_tokens_map.json',\n",
       " 'vit-gpt-model/vocab.json',\n",
       " 'vit-gpt-model/merges.txt',\n",
       " 'vit-gpt-model/added_tokens.json',\n",
       " 'vit-gpt-model/tokenizer.json')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir = \"vit-gpt-model\"\n",
    "model.save_pretrained(output_dir)\n",
    "feature_extractor.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b88b8dd",
   "metadata": {},
   "source": [
    "## Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0d1bced0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths data\n",
    "image_dir = './all_data/train/radiology/images/'\n",
    "data_file = './all_data/train/radiology/traindata.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a24cb4f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROCO_00002</td>\n",
       "      <td>PMC4083729_AMHSR-4-14-g002.jpg</td>\n",
       "      <td>Computed tomography scan in axial view showin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROCO_00003</td>\n",
       "      <td>PMC2837471_IJD2009-150251.001.jpg</td>\n",
       "      <td>Bacterial contamination occurred after comple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ROCO_00004</td>\n",
       "      <td>PMC2505281_11999_2007_30_Fig6_HTML.jpg</td>\n",
       "      <td>The patient had residual paralysis of the han...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROCO_00005</td>\n",
       "      <td>PMC3745845_IJD2013-683423.005.jpg</td>\n",
       "      <td>Panoramic radiograph after immediate loading.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ROCO_00007</td>\n",
       "      <td>PMC4917066_amjcaserep-17-301-g001.jpg</td>\n",
       "      <td>Plain abdomen x-ray: Multiple air levels at t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65445</th>\n",
       "      <td>ROCO_81819</td>\n",
       "      <td>PMC3517833_CRIM.HEMATOLOGY2012-490438.001.jpg</td>\n",
       "      <td>Initial CT abdomen with contrast showing a di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65446</th>\n",
       "      <td>ROCO_81820</td>\n",
       "      <td>PMC5487234_rb-50-03-0190-g13.jpg</td>\n",
       "      <td>44-year-old male patient after surgical amput...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65447</th>\n",
       "      <td>ROCO_81821</td>\n",
       "      <td>PMC2974222_kjr-11-612-g001.jpg</td>\n",
       "      <td>Primary pulmonary tuberculosis in 18-year-old...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65448</th>\n",
       "      <td>ROCO_81822</td>\n",
       "      <td>PMC3532764_AJNS-7-151-g002.jpg</td>\n",
       "      <td>MRI brain with gadolinium, coronal view, show...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65449</th>\n",
       "      <td>ROCO_81823</td>\n",
       "      <td>PMC3509000_pone.0050319.g002.jpg</td>\n",
       "      <td>Contrast-enhanced 3D MRL image of the lower e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65450 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                           name  \\\n",
       "0      ROCO_00002                 PMC4083729_AMHSR-4-14-g002.jpg   \n",
       "1      ROCO_00003              PMC2837471_IJD2009-150251.001.jpg   \n",
       "2      ROCO_00004         PMC2505281_11999_2007_30_Fig6_HTML.jpg   \n",
       "3      ROCO_00005              PMC3745845_IJD2013-683423.005.jpg   \n",
       "4      ROCO_00007          PMC4917066_amjcaserep-17-301-g001.jpg   \n",
       "...           ...                                            ...   \n",
       "65445  ROCO_81819  PMC3517833_CRIM.HEMATOLOGY2012-490438.001.jpg   \n",
       "65446  ROCO_81820               PMC5487234_rb-50-03-0190-g13.jpg   \n",
       "65447  ROCO_81821                 PMC2974222_kjr-11-612-g001.jpg   \n",
       "65448  ROCO_81822                 PMC3532764_AJNS-7-151-g002.jpg   \n",
       "65449  ROCO_81823               PMC3509000_pone.0050319.g002.jpg   \n",
       "\n",
       "                                                 caption  \n",
       "0       Computed tomography scan in axial view showin...  \n",
       "1       Bacterial contamination occurred after comple...  \n",
       "2       The patient had residual paralysis of the han...  \n",
       "3        Panoramic radiograph after immediate loading.\\n  \n",
       "4       Plain abdomen x-ray: Multiple air levels at t...  \n",
       "...                                                  ...  \n",
       "65445   Initial CT abdomen with contrast showing a di...  \n",
       "65446   44-year-old male patient after surgical amput...  \n",
       "65447   Primary pulmonary tuberculosis in 18-year-old...  \n",
       "65448   MRI brain with gadolinium, coronal view, show...  \n",
       "65449   Contrast-enhanced 3D MRL image of the lower e...  \n",
       "\n",
       "[65450 rows x 3 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(data_file)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "fc76a380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>caption</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROCO_00002</td>\n",
       "      <td>Computed tomography scan in axial view showin...</td>\n",
       "      <td>./all_data/train/radiology/images/PMC4083729_A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROCO_00003</td>\n",
       "      <td>Bacterial contamination occurred after comple...</td>\n",
       "      <td>./all_data/train/radiology/images/PMC2837471_I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ROCO_00004</td>\n",
       "      <td>The patient had residual paralysis of the han...</td>\n",
       "      <td>./all_data/train/radiology/images/PMC2505281_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROCO_00005</td>\n",
       "      <td>Panoramic radiograph after immediate loading.\\n</td>\n",
       "      <td>./all_data/train/radiology/images/PMC3745845_I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ROCO_00007</td>\n",
       "      <td>Plain abdomen x-ray: Multiple air levels at t...</td>\n",
       "      <td>./all_data/train/radiology/images/PMC4917066_a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65445</th>\n",
       "      <td>ROCO_81819</td>\n",
       "      <td>Initial CT abdomen with contrast showing a di...</td>\n",
       "      <td>./all_data/train/radiology/images/PMC3517833_C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65446</th>\n",
       "      <td>ROCO_81820</td>\n",
       "      <td>44-year-old male patient after surgical amput...</td>\n",
       "      <td>./all_data/train/radiology/images/PMC5487234_r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65447</th>\n",
       "      <td>ROCO_81821</td>\n",
       "      <td>Primary pulmonary tuberculosis in 18-year-old...</td>\n",
       "      <td>./all_data/train/radiology/images/PMC2974222_k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65448</th>\n",
       "      <td>ROCO_81822</td>\n",
       "      <td>MRI brain with gadolinium, coronal view, show...</td>\n",
       "      <td>./all_data/train/radiology/images/PMC3532764_A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65449</th>\n",
       "      <td>ROCO_81823</td>\n",
       "      <td>Contrast-enhanced 3D MRL image of the lower e...</td>\n",
       "      <td>./all_data/train/radiology/images/PMC3509000_p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65450 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                            caption  \\\n",
       "0      ROCO_00002   Computed tomography scan in axial view showin...   \n",
       "1      ROCO_00003   Bacterial contamination occurred after comple...   \n",
       "2      ROCO_00004   The patient had residual paralysis of the han...   \n",
       "3      ROCO_00005    Panoramic radiograph after immediate loading.\\n   \n",
       "4      ROCO_00007   Plain abdomen x-ray: Multiple air levels at t...   \n",
       "...           ...                                                ...   \n",
       "65445  ROCO_81819   Initial CT abdomen with contrast showing a di...   \n",
       "65446  ROCO_81820   44-year-old male patient after surgical amput...   \n",
       "65447  ROCO_81821   Primary pulmonary tuberculosis in 18-year-old...   \n",
       "65448  ROCO_81822   MRI brain with gadolinium, coronal view, show...   \n",
       "65449  ROCO_81823   Contrast-enhanced 3D MRL image of the lower e...   \n",
       "\n",
       "                                              image_path  \n",
       "0      ./all_data/train/radiology/images/PMC4083729_A...  \n",
       "1      ./all_data/train/radiology/images/PMC2837471_I...  \n",
       "2      ./all_data/train/radiology/images/PMC2505281_1...  \n",
       "3      ./all_data/train/radiology/images/PMC3745845_I...  \n",
       "4      ./all_data/train/radiology/images/PMC4917066_a...  \n",
       "...                                                  ...  \n",
       "65445  ./all_data/train/radiology/images/PMC3517833_C...  \n",
       "65446  ./all_data/train/radiology/images/PMC5487234_r...  \n",
       "65447  ./all_data/train/radiology/images/PMC2974222_k...  \n",
       "65448  ./all_data/train/radiology/images/PMC3532764_A...  \n",
       "65449  ./all_data/train/radiology/images/PMC3509000_p...  \n",
       "\n",
       "[65450 rows x 3 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace column name 'name' with 'image_path'\n",
    "data['image_path'] = data.pop('name')\n",
    "\n",
    "# Prepend 'image_dir' to all entries in 'image_path' column\n",
    "data['image_path'] = image_dir + data['image_path']\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1d187f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>relationship</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROCO_00002</td>\n",
       "      <td>with a mass of homogeneous attenuation (necro...</td>\n",
       "      <td>The patient has undergone a CT scan which sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROCO_00003</td>\n",
       "      <td>The patient developed pain and discomfort on ...</td>\n",
       "      <td>The patient developed pain and discomfort on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ROCO_00007</td>\n",
       "      <td>The given UMLS semantic types are 1. Radiogra...</td>\n",
       "      <td>There is no single UMLS semantic type that re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROCO_00008</td>\n",
       "      <td>or edema. There are no other abnormalities.\\n...</td>\n",
       "      <td>as follows: 1. Intellectual Product , 2. Phar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ROCO_00009</td>\n",
       "      <td>The patient was treated with K-wire and cannu...</td>\n",
       "      <td>\\nThe UMLS concept DIAGNOSIS has many children...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>ROCO_01327</td>\n",
       "      <td>Pseudoaneurysm is a Pathologic Function with ...</td>\n",
       "      <td>Pseudoaneurysm is a Pathologic Function with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>ROCO_01329</td>\n",
       "      <td>The answer is Causative Agent: Bacterium.</td>\n",
       "      <td>\\nCausative Agent: Bacterium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>ROCO_01330</td>\n",
       "      <td>and ascites with dilated veins at the periphe...</td>\n",
       "      <td>No new information.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>ROCO_01332</td>\n",
       "      <td>.\\nThe UMLS semantic types are 1. Body Part, O...</td>\n",
       "      <td>The given UMLS semantic types are 1. Diagnost...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>ROCO_01333</td>\n",
       "      <td>was provided by Dr. C from Wikimedia Commons....</td>\n",
       "      <td>There are no known relationships between UMLS...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>801 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                       relationship  \\\n",
       "0    ROCO_00002   with a mass of homogeneous attenuation (necro...   \n",
       "1    ROCO_00003   The patient developed pain and discomfort on ...   \n",
       "2    ROCO_00007   The given UMLS semantic types are 1. Radiogra...   \n",
       "3    ROCO_00008   or edema. There are no other abnormalities.\\n...   \n",
       "4    ROCO_00009   The patient was treated with K-wire and cannu...   \n",
       "..          ...                                                ...   \n",
       "796  ROCO_01327   Pseudoaneurysm is a Pathologic Function with ...   \n",
       "797  ROCO_01329          The answer is Causative Agent: Bacterium.   \n",
       "798  ROCO_01330   and ascites with dilated veins at the periphe...   \n",
       "799  ROCO_01332  .\\nThe UMLS semantic types are 1. Body Part, O...   \n",
       "800  ROCO_01333   was provided by Dr. C from Wikimedia Commons....   \n",
       "\n",
       "                                               summary  \n",
       "0     The patient has undergone a CT scan which sho...  \n",
       "1     The patient developed pain and discomfort on ...  \n",
       "2     There is no single UMLS semantic type that re...  \n",
       "3     as follows: 1. Intellectual Product , 2. Phar...  \n",
       "4    \\nThe UMLS concept DIAGNOSIS has many children...  \n",
       "..                                                 ...  \n",
       "796   Pseudoaneurysm is a Pathologic Function with ...  \n",
       "797                       \\nCausative Agent: Bacterium  \n",
       "798                                No new information.  \n",
       "799   The given UMLS semantic types are 1. Diagnost...  \n",
       "800   There are no known relationships between UMLS...  \n",
       "\n",
       "[801 rows x 3 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LLM output\n",
    "f = open('./all_data/llm_result.txt', \"r\")\n",
    "contents = f.read()\n",
    "contents = contents.replace(\"\\n\", \"\")\n",
    "json_data = json.loads(contents)\n",
    "\n",
    "llm_df = pd.DataFrame(json_data)\n",
    "\n",
    "llm_df = llm_df.drop('index', axis=1)\n",
    "\n",
    "llm_df = llm_df[llm_df['relationship'].apply(lambda x: re.search(r'\\w', str(x)) is not None)]\n",
    "llm_df = llm_df.reset_index(drop=True)\n",
    "\n",
    "llm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0b653b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>caption</th>\n",
       "      <th>image_path</th>\n",
       "      <th>relationship</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROCO_00002</td>\n",
       "      <td>Computed tomography scan in axial view showin...</td>\n",
       "      <td>./all_data/train/radiology/images/PMC4083729_A...</td>\n",
       "      <td>with a mass of homogeneous attenuation (necro...</td>\n",
       "      <td>The patient has undergone a CT scan which sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROCO_00003</td>\n",
       "      <td>Bacterial contamination occurred after comple...</td>\n",
       "      <td>./all_data/train/radiology/images/PMC2837471_I...</td>\n",
       "      <td>The patient developed pain and discomfort on ...</td>\n",
       "      <td>The patient developed pain and discomfort on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ROCO_00007</td>\n",
       "      <td>Plain abdomen x-ray: Multiple air levels at t...</td>\n",
       "      <td>./all_data/train/radiology/images/PMC4917066_a...</td>\n",
       "      <td>The given UMLS semantic types are 1. Radiogra...</td>\n",
       "      <td>There is no single UMLS semantic type that re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROCO_00008</td>\n",
       "      <td>A 3-year-old child with visual difficulties. ...</td>\n",
       "      <td>./all_data/train/radiology/images/PMC4805615_1...</td>\n",
       "      <td>or edema. There are no other abnormalities.\\n...</td>\n",
       "      <td>as follows: 1. Intellectual Product , 2. Phar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ROCO_00009</td>\n",
       "      <td>Showing the subtrochanteric fracture in the p...</td>\n",
       "      <td>./all_data/train/radiology/images/PMC2584650_1...</td>\n",
       "      <td>The patient was treated with K-wire and cannu...</td>\n",
       "      <td>\\nThe UMLS concept DIAGNOSIS has many children...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>ROCO_01327</td>\n",
       "      <td>Control angiography showed total exclusion of...</td>\n",
       "      <td>./all_data/train/radiology/images/PMC4396546_C...</td>\n",
       "      <td>Pseudoaneurysm is a Pathologic Function with ...</td>\n",
       "      <td>Pseudoaneurysm is a Pathologic Function with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>ROCO_01329</td>\n",
       "      <td>Abdominal CT finding. Enterocutaneous fistula...</td>\n",
       "      <td>./all_data/train/radiology/images/PMC4316223_i...</td>\n",
       "      <td>The answer is Causative Agent: Bacterium.</td>\n",
       "      <td>\\nCausative Agent: Bacterium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>ROCO_01330</td>\n",
       "      <td>(Case 2) Post operative CT scan showing persi...</td>\n",
       "      <td>./all_data/train/radiology/images/PMC3589860_J...</td>\n",
       "      <td>and ascites with dilated veins at the periphe...</td>\n",
       "      <td>No new information.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>ROCO_01332</td>\n",
       "      <td>Post-operative chest X-ray image of the same ...</td>\n",
       "      <td>./all_data/train/radiology/images/PMC4262879_W...</td>\n",
       "      <td>.\\nThe UMLS semantic types are 1. Body Part, O...</td>\n",
       "      <td>The given UMLS semantic types are 1. Diagnost...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>ROCO_01333</td>\n",
       "      <td>TTE image of the above shown malignant cardia...</td>\n",
       "      <td>./all_data/train/radiology/images/PMC3832829_A...</td>\n",
       "      <td>was provided by Dr. C from Wikimedia Commons....</td>\n",
       "      <td>There are no known relationships between UMLS...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>801 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                            caption  \\\n",
       "0    ROCO_00002   Computed tomography scan in axial view showin...   \n",
       "1    ROCO_00003   Bacterial contamination occurred after comple...   \n",
       "2    ROCO_00007   Plain abdomen x-ray: Multiple air levels at t...   \n",
       "3    ROCO_00008   A 3-year-old child with visual difficulties. ...   \n",
       "4    ROCO_00009   Showing the subtrochanteric fracture in the p...   \n",
       "..          ...                                                ...   \n",
       "796  ROCO_01327   Control angiography showed total exclusion of...   \n",
       "797  ROCO_01329   Abdominal CT finding. Enterocutaneous fistula...   \n",
       "798  ROCO_01330   (Case 2) Post operative CT scan showing persi...   \n",
       "799  ROCO_01332   Post-operative chest X-ray image of the same ...   \n",
       "800  ROCO_01333   TTE image of the above shown malignant cardia...   \n",
       "\n",
       "                                            image_path  \\\n",
       "0    ./all_data/train/radiology/images/PMC4083729_A...   \n",
       "1    ./all_data/train/radiology/images/PMC2837471_I...   \n",
       "2    ./all_data/train/radiology/images/PMC4917066_a...   \n",
       "3    ./all_data/train/radiology/images/PMC4805615_1...   \n",
       "4    ./all_data/train/radiology/images/PMC2584650_1...   \n",
       "..                                                 ...   \n",
       "796  ./all_data/train/radiology/images/PMC4396546_C...   \n",
       "797  ./all_data/train/radiology/images/PMC4316223_i...   \n",
       "798  ./all_data/train/radiology/images/PMC3589860_J...   \n",
       "799  ./all_data/train/radiology/images/PMC4262879_W...   \n",
       "800  ./all_data/train/radiology/images/PMC3832829_A...   \n",
       "\n",
       "                                          relationship  \\\n",
       "0     with a mass of homogeneous attenuation (necro...   \n",
       "1     The patient developed pain and discomfort on ...   \n",
       "2     The given UMLS semantic types are 1. Radiogra...   \n",
       "3     or edema. There are no other abnormalities.\\n...   \n",
       "4     The patient was treated with K-wire and cannu...   \n",
       "..                                                 ...   \n",
       "796   Pseudoaneurysm is a Pathologic Function with ...   \n",
       "797          The answer is Causative Agent: Bacterium.   \n",
       "798   and ascites with dilated veins at the periphe...   \n",
       "799  .\\nThe UMLS semantic types are 1. Body Part, O...   \n",
       "800   was provided by Dr. C from Wikimedia Commons....   \n",
       "\n",
       "                                               summary  \n",
       "0     The patient has undergone a CT scan which sho...  \n",
       "1     The patient developed pain and discomfort on ...  \n",
       "2     There is no single UMLS semantic type that re...  \n",
       "3     as follows: 1. Intellectual Product , 2. Phar...  \n",
       "4    \\nThe UMLS concept DIAGNOSIS has many children...  \n",
       "..                                                 ...  \n",
       "796   Pseudoaneurysm is a Pathologic Function with ...  \n",
       "797                       \\nCausative Agent: Bacterium  \n",
       "798                                No new information.  \n",
       "799   The given UMLS semantic types are 1. Diagnost...  \n",
       "800   There are no known relationships between UMLS...  \n",
       "\n",
       "[801 rows x 5 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter ones that have been training by the LLM\n",
    "data = data.merge(llm_df, on='id')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6b14299c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into train, test, and valid datasets\n",
    "train_data, valid_test_data = train_test_split(data, test_size=test_valid_percentage/100, random_state=42)\n",
    "valid_data, test_data = train_test_split(valid_test_data, test_size=0.5, random_state=42)\n",
    "\n",
    "# Reset index\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "valid_data = valid_data.reset_index(drop=True)\n",
    "test_data = test_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f4b6333b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (640, 5)\n",
      "Valid data shape:  (80, 5)\n",
      "Test data shape:  (81, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data shape: \", train_data.shape)\n",
    "print(\"Valid data shape: \", valid_data.shape)\n",
    "print(\"Test data shape: \", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "22fdcf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select n% of data\n",
    "train_data = train_data.sample(frac=train_data_percentage/100, random_state=42)\n",
    "valid_data = valid_data.sample(frac=valid_data_percentage/100, random_state=42)\n",
    "test_data = test_data.sample(frac=test_data_percentage/100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3e9ce7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'caption', 'image_path', 'relationship', 'summary', '__index_level_0__'],\n",
      "        num_rows: 128\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'caption', 'image_path', 'relationship', 'summary', '__index_level_0__'],\n",
      "        num_rows: 32\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'caption', 'image_path', 'relationship', 'summary', '__index_level_0__'],\n",
      "        num_rows: 32\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# Convert DataFrame to Hugging Face dataset dictionary format\n",
    "train_data_dict = Dataset.from_pandas(train_data)\n",
    "valid_data_dict = Dataset.from_pandas(valid_data)\n",
    "test_data_dict = Dataset.from_pandas(test_data)\n",
    "\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': train_data_dict,\n",
    "    'validation': valid_data_dict,\n",
    "    'test': test_data_dict\n",
    "})\n",
    "\n",
    "print(dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b2c229b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "\n",
    "# # text preprocessing step\n",
    "# def tokenization_fn(captions, max_target_length):\n",
    "#     \"\"\"Run tokenization on captions.\"\"\"\n",
    "#     labels = tokenizer(captions, \n",
    "#                       padding=\"max_length\", \n",
    "#                       max_length=max_target_length).input_ids\n",
    "\n",
    "#     return labels\n",
    "\n",
    "# # image preprocessing step\n",
    "# def preprocess_images(image_paths):\n",
    "#     processed_images = []\n",
    "#     for image_path in image_paths:\n",
    "#         image = Image.open(image_path)\n",
    "#         if image.mode != \"RGB\":\n",
    "#             image = image.convert(\"RGB\")\n",
    "#         processed_images.append(image)\n",
    "#     return processed_images\n",
    "\n",
    "# def feature_extraction_fn(image_paths, check_image=True):\n",
    "#     if check_image:\n",
    "#         images = preprocess_images(image_paths)\n",
    "#     else:\n",
    "#         images = [Image.open(image_file) for image_file in image_paths]\n",
    "\n",
    "#     encoder_inputs = feature_extractor(images=images, return_tensors=\"np\")\n",
    "\n",
    "#     return encoder_inputs.pixel_values\n",
    "\n",
    "# # def feature_extraction_fn(image_paths, check_image=True):\n",
    "# #     \"\"\"\n",
    "# #     Run feature extraction on images\n",
    "# #     If `check_image` is `True`, the examples that fails during `Image.open()` will be caught and discarded.\n",
    "# #     Otherwise, an exception will be thrown.\n",
    "# #     \"\"\"\n",
    "# #     model_inputs = {}\n",
    "\n",
    "# #     if check_image:\n",
    "# #         images = []\n",
    "# #         to_keep = []\n",
    "# #         for image_file in image_paths:\n",
    "# #             try:\n",
    "# #                 img = Image.open(image_file)\n",
    "# #                 images.append(img)\n",
    "# #                 to_keep.append(True)\n",
    "# #             except Exception:\n",
    "# #                 to_keep.append(False)\n",
    "# #     else:\n",
    "# #         images = [Image.open(image_file) for image_file in image_paths]\n",
    "\n",
    "# #     encoder_inputs = feature_extractor(images=images, return_tensors=\"np\")\n",
    "\n",
    "# #     return encoder_inputs.pixel_values\n",
    "\n",
    "# def preprocess_fn(examples, max_target_length, check_image = True):\n",
    "#     \"\"\"Run tokenization + image feature extraction\"\"\"\n",
    "#     image_paths = examples['image_path']\n",
    "#     captions = examples['caption']    \n",
    "    \n",
    "#     model_inputs = {}\n",
    "#     # This contains image path column\n",
    "#     model_inputs['labels'] = tokenization_fn(captions, max_target_length)\n",
    "#     model_inputs['pixel_values'] = feature_extraction_fn(image_paths, check_image=check_image)\n",
    "\n",
    "#     return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d3e6d09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "class ImageCapatioingDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, ds, ds_type, max_target_length):\n",
    "        self.ds = ds\n",
    "        self.max_target_length = max_target_length\n",
    "        self.ds_type = ds_type\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.ds[self.ds_type]['image_path'][idx]\n",
    "        caption = self.ds[self.ds_type]['caption'][idx]\n",
    "        model_inputs = dict()\n",
    "        model_inputs['labels'] = self.tokenization_fn(caption, self.max_target_length)\n",
    "        model_inputs['pixel_values'] = self.feature_extraction_fn(image_path)\n",
    "        return model_inputs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds[self.ds_type])\n",
    "    \n",
    "    # text preprocessing step\n",
    "    def tokenization_fn(self, caption, max_target_length):\n",
    "        \"\"\"Run tokenization on caption.\"\"\"\n",
    "        labels = tokenizer(caption, \n",
    "                          padding=\"max_length\", \n",
    "                          max_length=max_target_length).input_ids\n",
    "\n",
    "        return labels\n",
    "\n",
    "    # image preprocessing step\n",
    "    def feature_extraction_fn(self, image_path):\n",
    "        image = Image.open(image_path)\n",
    "        if image.mode != \"RGB\":\n",
    "            image = image.convert(\"RGB\")\n",
    "\n",
    "        encoder_inputs = feature_extractor(images=image, return_tensors=\"np\")\n",
    "\n",
    "        return encoder_inputs.pixel_values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "35712927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_dataset = dataset_dict.map(\n",
    "#     function=preprocess_fn,\n",
    "#     batched=True,\n",
    "#     fn_kwargs={\"max_target_length\": 128},\n",
    "#     remove_columns=dataset_dict['train'].column_names\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ae008ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "edb0d045",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ImageCapatioingDataset(dataset_dict, 'train', 64)\n",
    "eval_ds = ImageCapatioingDataset(dataset_dict, 'validation', 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8342a3",
   "metadata": {},
   "source": [
    "## Define seq2seq training argumentsPermalink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e3d08f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    predict_with_generate=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    output_dir=\"./image-captioning-output\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aed89b5",
   "metadata": {},
   "source": [
    "## Define metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "67b8ff7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "metric = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "04005bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "ignore_pad_token_for_loss = True\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [label.strip() for label in labels]\n",
    "\n",
    "    # rougeLSum expects newline after each sentence\n",
    "    preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n",
    "    labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    if ignore_pad_token_for_loss:\n",
    "        # Replace -100 in the labels as we can't decode them.\n",
    "        labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Some simple post-processing\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds,\n",
    "                                                     decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds,\n",
    "                            references=decoded_labels,\n",
    "                            use_stemmer=True)\n",
    "    result = {k: round(v * 100, 4) for k, v in result.items()}\n",
    "    prediction_lens = [\n",
    "        np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds\n",
    "    ]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6ed7ff",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e518ec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import default_data_collator\n",
    "\n",
    "# # instantiate trainer\n",
    "# trainer = Seq2SeqTrainer(\n",
    "#     model=model,\n",
    "#     tokenizer=feature_extractor,\n",
    "#     args=training_args,\n",
    "#     compute_metrics=compute_metrics,\n",
    "#     train_dataset=processed_dataset['train'],\n",
    "#     eval_dataset=processed_dataset['validation'],\n",
    "#     data_collator=default_data_collator,\n",
    "# )\n",
    "\n",
    "# instantiate trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    tokenizer=feature_extractor,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=eval_ds,\n",
    "    data_collator=default_data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b02ddc5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohith/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Column image_path not in the dataset. Current columns in the dataset: ['labels', 'pixel_values']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wb/_rgrp9kx0wsds433bv835rc40000gn/T/ipykernel_30321/4032920361.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1643\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m         )\n\u001b[0;32m-> 1645\u001b[0;31m         return inner_training_loop(\n\u001b[0m\u001b[1;32m   1646\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1915\u001b[0m             \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1916\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1917\u001b[0m                 \u001b[0mtotal_batched_samples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mrng_to_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/wb/_rgrp9kx0wsds433bv835rc40000gn/T/ipykernel_30321/3251382476.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mcaption\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'caption'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2776\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: F811\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2777\u001b[0m         \u001b[0;34m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2778\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2780\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m_getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   2760\u001b[0m         \u001b[0mformat_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat_kwargs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mformat_kwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2761\u001b[0m         \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mformat_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2762\u001b[0;31m         \u001b[0mpa_subtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_indices\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_indices\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2763\u001b[0m         formatted_output = format_table(\n\u001b[1;32m   2764\u001b[0m             \u001b[0mpa_subtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_all_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_all_columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36mquery_table\u001b[0;34m(table, key, indices)\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0m_raise_bad_key_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m         \u001b[0m_check_valid_column_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_rows\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36m_check_valid_column_key\u001b[0;34m(key, columns)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_check_valid_column_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Column {key} not in the dataset. Current columns in the dataset: {columns}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Column image_path not in the dataset. Current columns in the dataset: ['labels', 'pixel_values']\""
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc19f61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc172dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61777967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5717732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define your ImageCaptionDataset class for loading and preprocessing the data\n",
    "class ImageCaptionDataset(Dataset):\n",
    "    def __init__(self, image_paths, captions, transform):\n",
    "        self.image_paths = image_paths\n",
    "        self.captions = captions\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.image_paths[index]\n",
    "        caption = self.captions[index]\n",
    "        image = self.transform(image_path)\n",
    "        return image, caption\n",
    "\n",
    "# Set your hyperparameters and configurations\n",
    "image_dir = \"path/to/images\"\n",
    "caption_file = \"path/to/captions.txt\"\n",
    "batch_size = 32\n",
    "embedding_dim = 256\n",
    "hidden_dim = 512\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "# Load and preprocess your dataset\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = image.resize((224, 224))\n",
    "    image = transforms.ToTensor()(image)\n",
    "    image = transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))(image)\n",
    "    return image\n",
    "\n",
    "image_paths = [...]  # List of image file paths\n",
    "captions = [...]  # List of corresponding captions\n",
    "\n",
    "transform = preprocess_image\n",
    "dataset = ImageCaptionDataset(image_paths, captions, transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize the ViT feature extractor and tokenizer\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "\n",
    "# Initialize the ViT-based image captioning model\n",
    "model = ViTForImageCaptioning.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "\n",
    "# Define your loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
